{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95092025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import ApiFetcher\n",
    "from utils import distribution_calculating, check_distribution\n",
    "\n",
    "api = ApiFetcher(2015, 2025)\n",
    "df = api.get_dataframe('leaguegamelog')\n",
    "df['total_pts'] = df['home_pts'] + df['away_pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicTeamStateModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Dynamic Team State Embeddings for NBA total points prediction.\n",
    "    - Predykcja: wyłącznie z pary stanów (s_home, s_away) + home_flag. Zero dostępu do bieżących statystyk.\n",
    "    - Aktualizacja stanu: po meczu, z użyciem sygnałów z tego meczu (np. own_pts, opp_pts, total, margin).\n",
    "    - Loss poza klasą: MAE/Huber na przewidywanym totalu.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_teams: int,\n",
    "        state_dim: int = 64,\n",
    "        predictor_hidden: int = 128,\n",
    "        signals_dim: int = 4,  # np. [own_pts, opp_pts, total, margin]\n",
    "        use_layernorm: bool = True,\n",
    "        predictor_dropout: float = 0.15\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.signals_dim = signals_dim\n",
    "\n",
    "        # Learnable initial state per team (używane do inicjalizacji i przeniesienia między sezonami)\n",
    "        self.team_init = nn.Embedding(num_teams, state_dim)\n",
    "\n",
    "        # Home/away bias może zostać wyuczony implicite, ale dodajemy home_flag do predyktora\n",
    "        # Interakcje: concat[s_h, s_a, s_h*s_a, |s_h - s_a|, home_flag]\n",
    "        pred_in = state_dim * 4 + 1\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(pred_in, predictor_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(predictor_dropout),\n",
    "            nn.Linear(predictor_hidden, predictor_hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(predictor_hidden // 2, 1)\n",
    "        )\n",
    "\n",
    "        # Updater: GRUCell z wejściem [signals, opponent_state, home_flag] i stanem = current_state\n",
    "        self.updater = nn.GRUCell(\n",
    "            input_size=signals_dim + state_dim + 1,\n",
    "            hidden_size=state_dim\n",
    "        )\n",
    "\n",
    "        # Stabilizacja stanów\n",
    "        self.use_layernorm = use_layernorm\n",
    "        if use_layernorm:\n",
    "            self.state_norm = nn.LayerNorm(state_dim)\n",
    "\n",
    "        # Sezonowy carry-over (uczona mieszanka poprzedniego stanu z stanem inicjalnym)\n",
    "        self._alpha = nn.Parameter(torch.tensor(0.0))  # sigmoid(alpha) w [0,1]\n",
    "\n",
    "    # ========== Predykcja ==========\n",
    "    @torch.no_grad()\n",
    "    def init_states(self, team_ids: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Zwraca stan początkowy drużyn (przed pierwszym meczem / na starcie sezonu).\n",
    "        team_ids: LongTensor [B]\n",
    "        return: FloatTensor [B, state_dim]\n",
    "        \"\"\"\n",
    "        s0 = self.team_init(team_ids)\n",
    "        return self.state_norm(s0) if self.use_layernorm else s0\n",
    "\n",
    "    def predict_total(self, s_home: torch.Tensor, s_away: torch.Tensor, home_flag: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predykcja totalu wyłącznie na podstawie stanów drużyn i home_flag.\n",
    "        s_home, s_away: [B, state_dim]\n",
    "        home_flag: [B, 1] (float 0/1)\n",
    "        return: [B]\n",
    "        \"\"\"\n",
    "        interaction = s_home * s_away\n",
    "        diff = torch.abs(s_home - s_away)\n",
    "        x = torch.cat([s_home, s_away, interaction, diff, home_flag], dim=-1)\n",
    "        y = self.predictor(x).squeeze(-1)\n",
    "        return y\n",
    "\n",
    "    # Alias forward -> predykcja (bez aktualizacji)\n",
    "    def forward(self, s_home: torch.Tensor, s_away: torch.Tensor, home_flag: torch.Tensor) -> torch.Tensor:\n",
    "        return self.predict_total(s_home, s_away, home_flag)\n",
    "\n",
    "    # ========== Aktualizacja stanów po meczu ==========\n",
    "    def update_team_state(\n",
    "        self,\n",
    "        s_team: torch.Tensor,         # [B, D] stan drużyny PRZED meczem\n",
    "        s_opp: torch.Tensor,          # [B, D] stan przeciwnika PRZED meczem\n",
    "        home_flag: torch.Tensor,      # [B, 1] 1 dla gospodarza, 0 dla gościa (z perspektywy s_team)\n",
    "        signals: torch.Tensor         # [B, signals_dim] np. [own_pts, opp_pts, total, margin_from_team_view]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Aktualizuje stan pojedynczej drużyny po meczu, używając tylko danych, które zaszły (no leakage).\n",
    "        Zależność od przeciwnika jest dozwolona (jego stan przedmeczowy).\n",
    "        \"\"\"\n",
    "        upd_in = torch.cat([signals, s_opp, home_flag], dim=-1)\n",
    "        s_new = self.updater(upd_in, s_team)\n",
    "        if self.use_layernorm:\n",
    "            s_new = self.state_norm(s_new)\n",
    "        return s_new\n",
    "\n",
    "    def update_both_teams(\n",
    "        self,\n",
    "        s_home: torch.Tensor, s_away: torch.Tensor,\n",
    "        signals_home: torch.Tensor, signals_away: torch.Tensor\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Wygodny helper: aktualizuje oba stany na podstawie sygnałów z meczu.\n",
    "        signals_home, signals_away: [B, signals_dim] (np. [home_pts, away_pts, total, margin])\n",
    "        Z perspektywy home: home_flag=1; z perspektywy away: home_flag=0.\n",
    "        \"\"\"\n",
    "        B = s_home.size(0)\n",
    "        home_flag_home = torch.ones(B, 1, device=s_home.device, dtype=s_home.dtype)\n",
    "        home_flag_away = torch.zeros(B, 1, device=s_home.device, dtype=s_home.dtype)\n",
    "\n",
    "        s_home_new = self.update_team_state(s_home, s_away, home_flag_home, signals_home)\n",
    "        s_away_new = self.update_team_state(s_away, s_home, home_flag_away, signals_away)\n",
    "        return s_home_new, s_away_new\n",
    "\n",
    "    # ========== Sezonowy carry-over ==========\n",
    "    def carry_over(\n",
    "        self,\n",
    "        prev_state: torch.Tensor,     # [B, D] stan z końca poprzedniego sezonu\n",
    "        team_ids: torch.Tensor,       # [B]\n",
    "        reset_mask: torch.Tensor      # [B, 1] bool/float: 1 gdy start nowego sezonu, 0 w przeciwnym razie\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Przy starcie sezonu miksuje poprzedni stan z inicjalnym: s = a*s_prev + (1-a)*s_init.\n",
    "        Poza startem sezonu zwraca prev_state.\n",
    "        \"\"\"\n",
    "        a = torch.sigmoid(self._alpha)  # w [0,1]\n",
    "        s_init = self.team_init(team_ids)\n",
    "        if self.use_layernorm:\n",
    "            s_init = self.state_norm(s_init)\n",
    "\n",
    "        mixed = a * prev_state + (1.0 - a) * s_init\n",
    "        # zastosuj tylko tam, gdzie reset_mask = 1\n",
    "        return mixed * reset_mask + prev_state * (1.0 - reset_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "319cd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values('date').reset_index(drop=True)\n",
    "split_idx = int(len(df_sorted) * 0.9)\n",
    "df_train = df_sorted.iloc[:split_idx].reset_index(drop=True)\n",
    "df_test  = df_sorted.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "# --- normalizatory dla updatera: tylko [own_pts, opp_pts] ---\n",
    "def _mk_signals_stats(df_):\n",
    "    h = df_['home_pts'].values\n",
    "    a = df_['away_pts'].values\n",
    "    mu = np.array([h.mean(), a.mean()], dtype=float)\n",
    "    sd = np.array([h.std()+1e-6, a.std()+1e-6], dtype=float)\n",
    "    return mu, sd\n",
    "\n",
    "sig_mu, sig_sd = _mk_signals_stats(df_train)\n",
    "\n",
    "def norm_sig_own_opp(own_pts, opp_pts):\n",
    "    x = np.array([own_pts, opp_pts], dtype=float)\n",
    "    x = (x - sig_mu) / sig_sd\n",
    "    return x\n",
    "\n",
    "# --- normalizacja targetu (do loss) ---\n",
    "tot_mu = float(df_train['total_pts'].mean())\n",
    "tot_sd = float(df_train['total_pts'].std() + 1e-6)\n",
    "\n",
    "num_teams = df['home_team_id'].nunique() + 1\n",
    "model = DynamicTeamStateModel(\n",
    "    num_teams=num_teams,\n",
    "    state_dim=64,\n",
    "    predictor_hidden=128,\n",
    "    signals_dim=2,\n",
    "    use_layernorm=True,\n",
    "    predictor_dropout=0.15\n",
    ").to(device)\n",
    "loss_fn = nn.SmoothL1Loss(beta=10.0)  # nieco szerszy próg Huber\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "grad_clip = 1.0\n",
    "tbptt_K = 12\n",
    "epochs = 10\n",
    "lambda_delta = 1e-4  # regularyzacja zmian stanów\n",
    "states = {}\n",
    "\n",
    "tot_mu_t = torch.tensor(tot_mu, device=device, dtype=torch.float32)\n",
    "tot_sd_t = torch.tensor(tot_sd, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53b20766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(team_idx: int) -> torch.Tensor:\n",
    "    s = states.get(team_idx)\n",
    "    if s is None:\n",
    "        team_id_tensor = torch.tensor([team_idx], dtype=torch.long, device=device)\n",
    "        s0 = model.init_states(team_id_tensor)[0]  # [D]\n",
    "        states[team_idx] = s0\n",
    "        return s0\n",
    "    return s\n",
    "\n",
    "def detach_all_states():\n",
    "    for k in list(states.keys()):\n",
    "        states[k] = states[k].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19f98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 done.\n",
      "Epoch 2/10 done.\n",
      "Epoch 3/10 done.\n",
      "Epoch 4/10 done.\n",
      "Epoch 5/10 done.\n",
      "Epoch 6/10 done.\n",
      "Epoch 7/10 done.\n",
      "Epoch 8/10 done.\n",
      "Epoch 9/10 done.\n",
      "Epoch 10/10 done.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    pending_losses = []\n",
    "    states.clear()\n",
    "    for row in df_train.itertuples(index=False):\n",
    "        # pre-game states (używaj home_team_id/away_team_id)\n",
    "        s_h = get_state(int(row.home_team_id)).unsqueeze(0).to(device)\n",
    "        s_a = get_state(int(row.away_team_id)).unsqueeze(0).to(device)\n",
    "\n",
    "        home_flag = torch.ones(1, 1, device=device, dtype=s_h.dtype)\n",
    "        y_pred = model(s_h, s_a, home_flag)\n",
    "        y_true = torch.tensor([row.total_pts], device=device, dtype=s_h.dtype)\n",
    "\n",
    "        y_pred_std = (y_pred - tot_mu_t) / tot_sd_t\n",
    "        y_true_std = (y_true - tot_mu_t) / tot_sd_t\n",
    "        base_loss = loss_fn(y_pred_std, y_true_std)\n",
    "\n",
    "        h_pts = float(row.home_pts); a_pts = float(row.away_pts)\n",
    "        sig_home = torch.tensor(norm_sig_own_opp(h_pts, a_pts), device=device, dtype=s_h.dtype).unsqueeze(0)\n",
    "        sig_away = torch.tensor(norm_sig_own_opp(a_pts, h_pts), device=device, dtype=s_h.dtype).unsqueeze(0)\n",
    "        assert sig_home.shape[-1] == model.signals_dim and sig_away.shape[-1] == model.signals_dim\n",
    "\n",
    "        s_h_new, s_a_new = model.update_both_teams(s_h, s_a, sig_home, sig_away)\n",
    "\n",
    "        delta_reg = ((s_h_new - s_h).pow(2).mean() + (s_a_new - s_a).pow(2).mean()) * lambda_delta\n",
    "        loss = base_loss + delta_reg\n",
    "        pending_losses.append(loss)\n",
    "\n",
    "        states[int(row.home_team_id)] = s_h_new.squeeze(0)\n",
    "        states[int(row.away_team_id)] = s_a_new.squeeze(0)\n",
    "\n",
    "        if len(pending_losses) >= tbptt_K:\n",
    "            total_loss = torch.stack(pending_losses).mean()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            total_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            pending_losses.clear()\n",
    "            detach_all_states()\n",
    "    if pending_losses:\n",
    "        total_loss = torch.stack(pending_losses).mean()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        total_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        pending_losses.clear()\n",
    "        detach_all_states()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b5e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE: 17.19 | Baseline RMSE: 21.43\n",
      "Test MAE: 24.30 | Test RMSE: 39.04\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_mae_mse(df_eval, model, device):\n",
    "    model.eval()\n",
    "    states_eval = {}\n",
    "\n",
    "    def get_state_eval(team_idx: int):\n",
    "        s = states_eval.get(team_idx)\n",
    "        if s is None:\n",
    "            t = torch.tensor([team_idx], dtype=torch.long, device=device)\n",
    "            s0 = model.init_states(t)[0]\n",
    "            states_eval[team_idx] = s0\n",
    "            return s0\n",
    "        return s\n",
    "\n",
    "    mae_sum, mse_sum, n = 0.0, 0.0, 0\n",
    "    for row in df_eval.sort_values('date').itertuples(index=False):\n",
    "        s_h = get_state_eval(int(row.home_team_id)).unsqueeze(0).to(device)\n",
    "        s_a = get_state_eval(int(row.away_team_id)).unsqueeze(0).to(device)\n",
    "\n",
    "        y_pred = model(s_h, s_a, torch.ones(1,1,device=device,dtype=s_h.dtype))\n",
    "        y_true = torch.tensor([row.total_pts], device=device, dtype=s_h.dtype)\n",
    "\n",
    "        err = (y_pred - y_true)\n",
    "        mae_sum += torch.abs(err).item()\n",
    "        mse_sum += (err.pow(2)).item()\n",
    "        n += 1\n",
    "\n",
    "        # update po meczu (te same normalizatory co w train)\n",
    "        h_pts, a_pts = float(row.home_pts), float(row.away_pts)\n",
    "        sig_home = torch.tensor(norm_sig_own_opp(h_pts, a_pts), device=device, dtype=s_h.dtype).unsqueeze(0)\n",
    "        sig_away = torch.tensor(norm_sig_own_opp(a_pts, h_pts), device=device, dtype=s_h.dtype).unsqueeze(0)\n",
    "        assert sig_home.shape[-1] == model.signals_dim and sig_away.shape[-1] == model.signals_dim\n",
    "\n",
    "        s_h_new, s_a_new = model.update_both_teams(s_h, s_a, sig_home, sig_away)\n",
    "        states_eval[int(row.home_team_id)] = s_h_new.squeeze(0).detach()\n",
    "        states_eval[int(row.away_team_id)] = s_a_new.squeeze(0).detach()\n",
    "\n",
    "    mae = mae_sum / max(n, 1)\n",
    "    mse = mse_sum / max(n, 1)\n",
    "    return mae, mse\n",
    "\n",
    "# baseline: stała średnia z train\n",
    "@torch.no_grad()\n",
    "def baseline_mae_mse(df_train, df_eval):\n",
    "    import numpy as np\n",
    "    mu = float(df_train['total_pts'].mean())\n",
    "    y = df_eval['total_pts'].to_numpy(dtype=float)\n",
    "    mae = np.abs(y - mu).mean()\n",
    "    mse = ((y - mu) ** 2).mean()\n",
    "    return mae, mse\n",
    "\n",
    "test_mae, test_mse = evaluate_mae_mse(df_test, model, device)\n",
    "base_mae, base_mse = baseline_mae_mse(df_train, df_test)\n",
    "print(f\"Baseline MAE: {base_mae:.2f} | Baseline RMSE: {base_mse**0.5:.2f}\")\n",
    "print(f\"Test MAE: {test_mae:.2f} | Test RMSE: {test_mse**0.5:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
