{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import ApiFetcher\n",
    "from utils import distribution_calculating, check_distribution\n",
    "from model import TeamEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ApiFetcher(2015, 2025)\n",
    "df = api.df_with_id()\n",
    "num_teams = len(df['home_team_id'].unique())\n",
    "model = TeamEmbeddings(num_teams=num_teams)\n",
    "\n",
    "print(f\"Model structure:\\n{sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Przygotuj dane\n",
    "feature_cols = ['home_fga', 'away_fga', 'home_fg_pct', 'away_fg_pct', \n",
    "               'home_fg3a', 'away_fg3a', 'home_fg3_pct', 'away_fg3_pct',\n",
    "               'home_oreb', 'away_oreb', 'home_dreb', 'away_dreb',\n",
    "               'home_ast', 'away_ast', 'home_stl', 'away_stl',\n",
    "               'home_blk', 'away_blk', 'home_tov', 'away_tov',\n",
    "               'home_pf', 'away_pf']\n",
    "\n",
    "X_features = torch.tensor(df[feature_cols].values, dtype=torch.float32)\n",
    "home_team_ids = torch.tensor(df['home_team_id'].values, dtype=torch.long)\n",
    "away_team_ids = torch.tensor(df['away_team_id'].values, dtype=torch.long)\n",
    "targets = torch.tensor(df['home_pts'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"✅ Data ready:\")\n",
    "print(f\"  Features: {X_features.shape}\")\n",
    "print(f\"  Targets: {targets.shape}\")\n",
    "print(f\"  Model params: 889\")\n",
    "print(f\"  Data/params ratio: {len(targets)/889:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fe9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(home_team_ids[:5], away_team_ids[:5], X_features[:5])\n",
    "    print(f\"Sample predictions: {test_pred.squeeze()}\")\n",
    "    print(f\"Actual targets:     {targets[:5]}\")\n",
    "    print(\"✅ Model is working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dodaj przed treningiem\n",
    "print(\"Weight ranges before training:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: min={param.min():.3f}, max={param.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67df18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the model can overfit a small sample\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Take only 10 samples\n",
    "small_sample = 10\n",
    "X_small = X_features[:small_sample]\n",
    "home_small = home_team_ids[:small_sample]\n",
    "away_small = away_team_ids[:small_sample]\n",
    "targets_small = targets[:small_sample]\n",
    "\n",
    "print(\"Test overfittingu do małej próbki:\")\n",
    "print(f\"Targets: {targets_small}\")\n",
    "\n",
    "# Train only on the small sample\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(home_small, away_small, X_small).squeeze()\n",
    "    loss = criterion(predictions, targets_small)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Dodaj gradient clipping dla bezpieczeństwa\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predictions: {predictions[:3].detach()}\")\n",
    "\n",
    "print(f\"\\nFinal predictions: {predictions.detach()}\")\n",
    "print(f\"Actual targets:    {targets_small}\")\n",
    "print(f\"Final loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, home_train, home_val, away_train, away_val, y_train, y_val = train_test_split(\n",
    "    X_features, home_team_ids, away_team_ids, targets, \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Validation size: {len(X_val)}\")\n",
    "\n",
    "# Create model for full training\n",
    "model_full = TeamEmbeddings(num_teams=num_teams)\n",
    "optimizer = torch.optim.Adam(model_full.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "model_full.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Training\n",
    "    optimizer.zero_grad()\n",
    "    train_pred = model_full(home_train, away_train, X_train).squeeze()\n",
    "    train_loss = criterion(train_pred, y_train)\n",
    "    train_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model_full.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model_full.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model_full(home_val, away_val, X_val).squeeze()\n",
    "        val_loss = criterion(val_pred, y_val)\n",
    "    model_full.train()\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss.item():.2f}, Val Loss: {val_loss.item():.2f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
