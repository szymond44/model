{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c28ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1a386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import ApiFetcher\n",
    "from model import TeamEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a643d4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:\n",
      "953 parameters\n"
     ]
    }
   ],
   "source": [
    "api = ApiFetcher(2015, 2025)\n",
    "df = api.get_dataframe(numeric=False, ids=True)\n",
    "num_teams = len(df['home_team_id'].unique())\n",
    "model = TeamEmbeddings(num_teams=num_teams)\n",
    "\n",
    "print(f\"Model structure:\\n{sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d1365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotuj dane\n",
    "feature_cols = ['home_fga', 'away_fga', 'home_fg_pct', 'away_fg_pct', \n",
    "               'home_fg3a', 'away_fg3a', 'home_fg3_pct', 'away_fg3_pct',\n",
    "               'home_oreb', 'away_oreb', 'home_dreb', 'away_dreb',\n",
    "               'home_ast', 'away_ast', 'home_stl', 'away_stl',\n",
    "               'home_blk', 'away_blk', 'home_tov', 'away_tov',\n",
    "               'home_pf', 'away_pf']\n",
    "\n",
    "X_features = torch.tensor(df[feature_cols].values, dtype=torch.float32)\n",
    "home_team_ids = torch.tensor(df['home_team_id'].values, dtype=torch.long)\n",
    "away_team_ids = torch.tensor(df['away_team_id'].values, dtype=torch.long)\n",
    "targets = torch.tensor(df['home_pts'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905d04a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data ready:\n",
      "  Features: torch.Size([11973, 22])\n",
      "  Targets: torch.Size([11973])\n",
      "  Model params: 889\n",
      "  Data/params ratio: 13.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Data ready:\")\n",
    "print(f\"  Features: {X_features.shape}\")\n",
    "print(f\"  Targets: {targets.shape}\")\n",
    "print(f\"  Model params: 889\")\n",
    "print(f\"  Data/params ratio: {len(targets)/889:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360fe9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions: tensor([-0.2058, -0.4275,  0.0507, -0.1570, -0.2136])\n",
      "Actual targets:     tensor([ 94.,  97., 111.,  97., 112.])\n",
      "✅ Model is working!\n"
     ]
    }
   ],
   "source": [
    "# Test forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(home_team_ids[:5], away_team_ids[:5], X_features[:5])\n",
    "    print(f\"Sample predictions: {test_pred.squeeze()}\")\n",
    "    print(f\"Actual targets:     {targets[:5]}\")\n",
    "    print(\"✅ Model is working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8dc5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight ranges before training:\n",
      "embedding.weight: min=-0.337, max=0.262\n",
      "feature_net.0.weight: min=-0.212, max=0.212\n",
      "feature_net.0.bias: min=-0.182, max=0.179\n",
      "feature_net.2.weight: min=-0.250, max=0.244\n",
      "feature_net.2.bias: min=-0.218, max=0.226\n",
      "final_net.0.weight: min=-0.203, max=0.204\n",
      "final_net.0.bias: min=-0.201, max=0.177\n",
      "final_net.2.weight: min=-0.335, max=0.338\n",
      "final_net.2.bias: min=0.012, max=0.012\n"
     ]
    }
   ],
   "source": [
    "# Dodaj przed treningiem\n",
    "print(\"Weight ranges before training:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: min={param.min():.3f}, max={param.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a67df18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test overfittingu do małej próbki:\n",
      "Targets: tensor([ 94.,  97., 111.,  97., 112.,  95.,  76., 104., 111., 112.])\n",
      "Epoch 0, Loss: 10344.0635, Predictions: tensor([-0.2058, -0.4275,  0.0507])\n",
      "Epoch 50, Loss: 83.5516, Predictions: tensor([101.5138,  99.1199, 113.0829])\n",
      "Epoch 100, Loss: 10.9588, Predictions: tensor([ 90.8592,  93.8344, 106.5650])\n",
      "Epoch 150, Loss: 12.1014, Predictions: tensor([ 90.5365,  93.4781, 107.1021])\n",
      "Epoch 200, Loss: 2.7293, Predictions: tensor([ 95.6251,  98.6275, 112.8380])\n",
      "Epoch 250, Loss: 7.4149, Predictions: tensor([ 96.6915,  99.7030, 114.0056])\n",
      "Epoch 300, Loss: 14.0922, Predictions: tensor([ 90.2982,  93.2819, 106.8518])\n",
      "Epoch 350, Loss: 3.1749, Predictions: tensor([ 92.2222,  95.2124, 109.0492])\n",
      "Epoch 400, Loss: 5.2856, Predictions: tensor([ 91.8159,  94.8009, 108.4493])\n",
      "Epoch 450, Loss: 8.4236, Predictions: tensor([ 96.8748,  99.8772, 114.1884])\n",
      "\n",
      "Final predictions: tensor([ 97.9631, 100.9722, 115.4038, 100.9861, 116.0654,  98.9586,  79.5253,\n",
      "        107.7582, 115.1575, 116.2226])\n",
      "Actual targets:    tensor([ 94.,  97., 111.,  97., 112.,  95.,  76., 104., 111., 112.])\n",
      "Final loss: 16.0630\n"
     ]
    }
   ],
   "source": [
    "# Checking whether the model can overfit a small sample\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Take only 10 samples\n",
    "small_sample = 10\n",
    "X_small = X_features[:small_sample]\n",
    "home_small = home_team_ids[:small_sample]\n",
    "away_small = away_team_ids[:small_sample]\n",
    "targets_small = targets[:small_sample]\n",
    "\n",
    "print(\"Test overfittingu do małej próbki:\")\n",
    "print(f\"Targets: {targets_small}\")\n",
    "\n",
    "# Train only on the small sample\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(home_small, away_small, X_small).squeeze()\n",
    "    loss = criterion(predictions, targets_small)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Dodaj gradient clipping dla bezpieczeństwa\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predictions: {predictions[:3].detach()}\")\n",
    "\n",
    "print(f\"\\nFinal predictions: {predictions.detach()}\")\n",
    "print(f\"Actual targets:    {targets_small}\")\n",
    "print(f\"Final loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dcbb7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 9578\n",
      "Validation size: 2395\n",
      "Epoch 0, Train Loss: 12722.87, Val Loss: 12588.77\n",
      "Epoch 20, Train Loss: 11854.89, Val Loss: 11734.86\n",
      "Epoch 40, Train Loss: 10500.94, Val Loss: 10343.90\n",
      "Epoch 60, Train Loss: 8202.57, Val Loss: 8003.70\n",
      "Epoch 80, Train Loss: 4802.92, Val Loss: 4574.79\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, home_train, home_val, away_train, away_val, y_train, y_val = train_test_split(\n",
    "    X_features, home_team_ids, away_team_ids, targets, \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Validation size: {len(X_val)}\")\n",
    "\n",
    "# Create model for full training\n",
    "model_full = TeamEmbeddings(num_teams=num_teams)\n",
    "optimizer = torch.optim.Adam(model_full.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "model_full.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Training\n",
    "    optimizer.zero_grad()\n",
    "    train_pred = model_full(home_train, away_train, X_train).squeeze()\n",
    "    train_loss = criterion(train_pred, y_train)\n",
    "    train_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model_full.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model_full.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model_full(home_val, away_val, X_val).squeeze()\n",
    "        val_loss = criterion(val_pred, y_val)\n",
    "    model_full.train()\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss.item():.2f}, Val Loss: {val_loss.item():.2f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
