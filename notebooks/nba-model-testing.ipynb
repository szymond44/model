{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import ApiFetcher\n",
    "from model import TeamEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a643d4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:\n",
      "953 parameters\n"
     ]
    }
   ],
   "source": [
    "api = ApiFetcher(2015, 2025)\n",
    "df = api.df_with_id()\n",
    "num_teams = len(df['home_team_id'].unique())\n",
    "model = TeamEmbeddings(num_teams=num_teams)\n",
    "\n",
    "print(f\"Model structure:\\n{sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotuj dane\n",
    "feature_cols = ['home_fga', 'away_fga', 'home_fg_pct', 'away_fg_pct', \n",
    "               'home_fg3a', 'away_fg3a', 'home_fg3_pct', 'away_fg3_pct',\n",
    "               'home_oreb', 'away_oreb', 'home_dreb', 'away_dreb',\n",
    "               'home_ast', 'away_ast', 'home_stl', 'away_stl',\n",
    "               'home_blk', 'away_blk', 'home_tov', 'away_tov',\n",
    "               'home_pf', 'away_pf']\n",
    "\n",
    "X_features = torch.tensor(df[feature_cols].values, dtype=torch.float32)\n",
    "home_team_ids = torch.tensor(df['home_team_id'].values, dtype=torch.long)\n",
    "away_team_ids = torch.tensor(df['away_team_id'].values, dtype=torch.long)\n",
    "targets = torch.tensor(df['home_pts'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905d04a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data ready:\n",
      "  Features: torch.Size([11973, 22])\n",
      "  Targets: torch.Size([11973])\n",
      "  Model params: 889\n",
      "  Data/params ratio: 13.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"✅ Data ready:\")\n",
    "print(f\"  Features: {X_features.shape}\")\n",
    "print(f\"  Targets: {targets.shape}\")\n",
    "print(f\"  Model params: 889\")\n",
    "print(f\"  Data/params ratio: {len(targets)/889:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360fe9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions: tensor([-0.3247, -0.2503, -0.3109, -0.4154, -0.2903])\n",
      "Actual targets:     tensor([ 94.,  97., 111.,  97., 112.])\n",
      "✅ Model is working!\n"
     ]
    }
   ],
   "source": [
    "# Test forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred = model(home_team_ids[:5], away_team_ids[:5], X_features[:5])\n",
    "    print(f\"Sample predictions: {test_pred.squeeze()}\")\n",
    "    print(f\"Actual targets:     {targets[:5]}\")\n",
    "    print(\"✅ Model is working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8dc5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight ranges before training:\n",
      "embedding.weight: min=-0.252, max=0.258\n",
      "feature_net.0.weight: min=-0.212, max=0.211\n",
      "feature_net.0.bias: min=-0.180, max=0.182\n",
      "feature_net.2.weight: min=-0.234, max=0.249\n",
      "feature_net.2.bias: min=-0.189, max=0.152\n",
      "final_net.0.weight: min=-0.196, max=0.195\n",
      "final_net.0.bias: min=-0.203, max=0.161\n",
      "final_net.2.weight: min=-0.250, max=0.275\n",
      "final_net.2.bias: min=-0.220, max=-0.220\n"
     ]
    }
   ],
   "source": [
    "# Dodaj przed treningiem\n",
    "print(\"Weight ranges before training:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: min={param.min():.3f}, max={param.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a67df18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test overfittingu do małej próbki:\n",
      "Targets: tensor([ 94.,  97., 111.,  97., 112.,  95.,  76., 104., 111., 112.])\n",
      "Epoch 0, Loss: 10354.9395, Predictions: tensor([-0.3247, -0.2503, -0.3109])\n",
      "Epoch 50, Loss: 107.0769, Predictions: tensor([ 97.9367,  97.3996, 103.9465])\n",
      "Epoch 100, Loss: 4.5868, Predictions: tensor([ 95.5536,  98.3861, 111.6864])\n",
      "Epoch 150, Loss: 0.6167, Predictions: tensor([ 94.7397,  97.9570, 111.4261])\n",
      "Epoch 200, Loss: 6.0748, Predictions: tensor([ 91.6115,  94.5941, 108.3622])\n",
      "Epoch 250, Loss: 4.7132, Predictions: tensor([ 96.1630,  99.1964, 113.3678])\n",
      "Epoch 300, Loss: 3.4003, Predictions: tensor([ 95.8335,  98.8508, 112.9993])\n",
      "Epoch 350, Loss: 4.1002, Predictions: tensor([ 91.9936,  94.9690, 108.8105])\n",
      "Epoch 400, Loss: 6.1081, Predictions: tensor([ 96.4543,  99.4720, 113.6726])\n",
      "Epoch 450, Loss: 4.3678, Predictions: tensor([ 96.0755,  99.0895, 113.2593])\n",
      "\n",
      "Final predictions: tensor([ 93.0269,  96.0115, 109.9357,  96.0297, 110.9866,  94.0277,  75.1731,\n",
      "        103.0703, 109.9800, 110.9512])\n",
      "Actual targets:    tensor([ 94.,  97., 111.,  97., 112.,  95.,  76., 104., 111., 112.])\n",
      "Final loss: 0.9659\n"
     ]
    }
   ],
   "source": [
    "# Checking whether the model can overfit a small sample\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Take only 10 samples\n",
    "small_sample = 10\n",
    "X_small = X_features[:small_sample]\n",
    "home_small = home_team_ids[:small_sample]\n",
    "away_small = away_team_ids[:small_sample]\n",
    "targets_small = targets[:small_sample]\n",
    "\n",
    "print(\"Test overfittingu do małej próbki:\")\n",
    "print(f\"Targets: {targets_small}\")\n",
    "\n",
    "# Train only on the small sample\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(home_small, away_small, X_small).squeeze()\n",
    "    loss = criterion(predictions, targets_small)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Dodaj gradient clipping dla bezpieczeństwa\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}, Predictions: {predictions[:3].detach()}\")\n",
    "\n",
    "print(f\"\\nFinal predictions: {predictions.detach()}\")\n",
    "print(f\"Actual targets:    {targets_small}\")\n",
    "print(f\"Final loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dcbb7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 9578\n",
      "Validation size: 2395\n",
      "Epoch 0, Train Loss: 12411.35, Val Loss: 12292.89\n",
      "Epoch 20, Train Loss: 11288.64, Val Loss: 11142.05\n",
      "Epoch 40, Train Loss: 9195.66, Val Loss: 8992.54\n",
      "Epoch 60, Train Loss: 5752.69, Val Loss: 5504.51\n",
      "Epoch 80, Train Loss: 1733.79, Val Loss: 1538.72\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, home_train, home_val, away_train, away_val, y_train, y_val = train_test_split(\n",
    "    X_features, home_team_ids, away_team_ids, targets, \n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\")\n",
    "print(f\"Validation size: {len(X_val)}\")\n",
    "\n",
    "# Create model for full training\n",
    "model_full = TeamEmbeddings(num_teams=num_teams)\n",
    "optimizer = torch.optim.Adam(model_full.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "model_full.train()\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Training\n",
    "    optimizer.zero_grad()\n",
    "    train_pred = model_full(home_train, away_train, X_train).squeeze()\n",
    "    train_loss = criterion(train_pred, y_train)\n",
    "    train_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model_full.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model_full.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model_full(home_val, away_val, X_val).squeeze()\n",
    "        val_loss = criterion(val_pred, y_val)\n",
    "    model_full.train()\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss.item():.2f}, Val Loss: {val_loss.item():.2f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
