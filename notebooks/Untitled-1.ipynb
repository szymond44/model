{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d3fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d182eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data.api_fetcher import ApiFetcher\n",
    "from model.team_embeddings import EmbeddingFetcher\n",
    "from model.team_embeddings import TeamEmbeddingsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba53cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ApiFetcher(starting_year=2019, ending_year=2025)\n",
    "df = api.get_dataframe(numeric=False, date=True, time_coeff=False, ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7955d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 18.45200906043242\n"
     ]
    }
   ],
   "source": [
    "trainer = TeamEmbeddingsModel(df)\n",
    "test_mse, trained_model = trainer.train()\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771d0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_embeddings = trained_model.home_embedding.weight.detach().cpu().numpy()\n",
    "away_embeddings = trained_model.away_embedding.weight.detach().cpu().numpy()\n",
    "embeddings_fetcher = EmbeddingFetcher(home_embeddings, away_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a3a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(df1, target_cols=['home_pts', 'away_pts'], scaler=None):\n",
    "    team_id_cols = ['home_team_id', 'away_team_id']\n",
    "    exclude_cols = target_cols + team_id_cols + ['date', 'home_team', 'away_team']\n",
    "    numeric_cols = [col for col in df1.columns if col not in exclude_cols]\n",
    "\n",
    "\n",
    "    X_numeric_raw = df1[numeric_cols].values\n",
    "    X_team_ids = df1[team_id_cols].astype(int).values\n",
    "    y = df1[target_cols].sum(axis=1).values\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X_numeric = scaler.fit_transform(X_numeric_raw)\n",
    "    else:\n",
    "        X_numeric = scaler.transform(X_numeric_raw)\n",
    "\n",
    "    return X_numeric, X_team_ids, y, scaler, numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6c4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBAEmbeddingDataset(Dataset):\n",
    "    def __init__(self, X_numeric, X_team_ids, y, fetcher):\n",
    "        self.X_numeric = torch.tensor(X_numeric, dtype=torch.float32)\n",
    "        self.X_team_ids = torch.tensor(X_team_ids, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.fetcher = fetcher\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        numeric_features = self.X_numeric[idx]\n",
    "        home_id, away_id = self.X_team_ids[idx]\n",
    "        # Fetch embeddings\n",
    "        home_emb = torch.tensor(self.fetcher.get_home_embedding(home_id), dtype=torch.float32)\n",
    "        away_emb = torch.tensor(self.fetcher.get_away_embedding(away_id), dtype=torch.float32)\n",
    "        return numeric_features, home_emb, away_emb, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a93920",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniNN(nn.Module):\n",
    "    def __init__(self, num_numeric_features, embedding_dim):\n",
    "        super(MiniNN, self).__init__()\n",
    "        input_size = num_numeric_features + embedding_dim*2\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, numeric_features, home_emb, away_emb):\n",
    "        x = torch.cat([numeric_features, home_emb, away_emb], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.out(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ed52b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, fetcher, embedding_dim, num_epochs, lr, batch_size=64,):\n",
    "    # Sort and split\n",
    "    df_sorted = df.sort_values(\"date\")\n",
    "    train_df, val_df, test_df = np.split(\n",
    "        df_sorted, \n",
    "        [int(0.7*len(df_sorted)), int(0.85*len(df_sorted))]\n",
    "    )\n",
    "    \n",
    "    X_train_num, X_train_ids, y_train, scaler, numeric_cols = prep_df(train_df)\n",
    "    X_val_num, X_val_ids, y_val, _, _ = prep_df(val_df, scaler=scaler)\n",
    "    X_test_num, X_test_ids, y_test, _, _ = prep_df(test_df, scaler=scaler)\n",
    "    \n",
    "    # Datasets\n",
    "    train_dataset = NBAEmbeddingDataset(X_train_num, X_train_ids, y_train, fetcher)\n",
    "    val_dataset = NBAEmbeddingDataset(X_val_num, X_val_ids, y_val, fetcher)\n",
    "    test_dataset = NBAEmbeddingDataset(X_test_num, X_test_ids, y_test, fetcher)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Model\n",
    "    num_numeric_features = X_train_num.shape[1]\n",
    "    model = MiniNN(num_numeric_features, embedding_dim)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_num, home_emb, away_emb, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X_num, home_emb, away_emb)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * X_num.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_num, home_emb, away_emb, y in val_loader:\n",
    "                pred = model(X_num, home_emb, away_emb)\n",
    "                val_loss += criterion(pred, y).item() * X_num.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Train MSE: {train_loss:.4f} | Val MSE: {val_loss:.4f}\")\n",
    "    \n",
    "    # Test MSE\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_num, home_emb, away_emb, y in test_loader:\n",
    "            pred = model(X_num, home_emb, away_emb)\n",
    "            test_loss += criterion(pred, y).item() * X_num.size(0)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test MSE: {test_loss:.4f}\")\n",
    "    \n",
    "    return model, scaler, numeric_cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51cdf854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/270 | Train MSE: 115.4103 | Val MSE: 124.0954\n",
      "Epoch 20/270 | Train MSE: 52.8090 | Val MSE: 59.0087\n",
      "Epoch 30/270 | Train MSE: 38.8426 | Val MSE: 46.7050\n",
      "Epoch 40/270 | Train MSE: 35.5091 | Val MSE: 42.1989\n",
      "Epoch 50/270 | Train MSE: 32.7131 | Val MSE: 43.6055\n",
      "Epoch 60/270 | Train MSE: 30.1163 | Val MSE: 42.5996\n",
      "Epoch 70/270 | Train MSE: 28.2149 | Val MSE: 41.6736\n",
      "Epoch 80/270 | Train MSE: 27.9489 | Val MSE: 48.2381\n",
      "Epoch 90/270 | Train MSE: 26.3216 | Val MSE: 43.0820\n",
      "Epoch 100/270 | Train MSE: 25.6309 | Val MSE: 42.2009\n",
      "Epoch 110/270 | Train MSE: 24.9162 | Val MSE: 45.8874\n",
      "Epoch 120/270 | Train MSE: 25.3220 | Val MSE: 42.7017\n",
      "Epoch 130/270 | Train MSE: 23.9628 | Val MSE: 45.2780\n",
      "Epoch 140/270 | Train MSE: 23.6932 | Val MSE: 43.7720\n",
      "Epoch 150/270 | Train MSE: 23.3272 | Val MSE: 48.8769\n",
      "Epoch 160/270 | Train MSE: 22.7800 | Val MSE: 44.9829\n",
      "Epoch 170/270 | Train MSE: 21.9843 | Val MSE: 43.7482\n",
      "Epoch 180/270 | Train MSE: 23.2504 | Val MSE: 43.8190\n",
      "Epoch 190/270 | Train MSE: 21.6494 | Val MSE: 44.4607\n",
      "Epoch 200/270 | Train MSE: 22.4088 | Val MSE: 46.2133\n",
      "Epoch 210/270 | Train MSE: 21.1743 | Val MSE: 47.5537\n",
      "Epoch 220/270 | Train MSE: 20.9677 | Val MSE: 44.1474\n",
      "Epoch 230/270 | Train MSE: 20.3533 | Val MSE: 47.8433\n",
      "Epoch 240/270 | Train MSE: 19.8917 | Val MSE: 49.7974\n",
      "Epoch 250/270 | Train MSE: 20.2743 | Val MSE: 47.8306\n",
      "Epoch 260/270 | Train MSE: 20.2006 | Val MSE: 45.5931\n",
      "Epoch 270/270 | Train MSE: 20.5310 | Val MSE: 45.5735\n",
      "Test MSE: 50.8442\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = home_embeddings.shape[1]\n",
    "model, scaler, numeric_cols = train_model(df, embeddings_fetcher, embedding_dim, num_epochs=270, lr=0.0008991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf99845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\szymo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/270 | Train MSE: 34.6675 | Val MSE: 36.3457\n",
      "Epoch 20/270 | Train MSE: 16.2516 | Val MSE: 18.7962\n",
      "Epoch 30/270 | Train MSE: 13.0286 | Val MSE: 16.6666\n",
      "Epoch 40/270 | Train MSE: 11.7982 | Val MSE: 15.0682\n",
      "Epoch 50/270 | Train MSE: 10.9088 | Val MSE: 15.5365\n",
      "Epoch 60/270 | Train MSE: 10.6084 | Val MSE: 15.0979\n",
      "Epoch 70/270 | Train MSE: 10.1883 | Val MSE: 15.5976\n",
      "Epoch 80/270 | Train MSE: 10.0737 | Val MSE: 15.2523\n",
      "Epoch 90/270 | Train MSE: 9.4923 | Val MSE: 14.9745\n",
      "Epoch 100/270 | Train MSE: 9.0354 | Val MSE: 15.1892\n",
      "Epoch 110/270 | Train MSE: 8.7994 | Val MSE: 14.4293\n",
      "Epoch 120/270 | Train MSE: 8.9456 | Val MSE: 18.7509\n",
      "Epoch 130/270 | Train MSE: 8.6737 | Val MSE: 16.7638\n",
      "Epoch 140/270 | Train MSE: 8.1362 | Val MSE: 14.8187\n",
      "Epoch 150/270 | Train MSE: 8.0911 | Val MSE: 15.0890\n",
      "Epoch 160/270 | Train MSE: 7.9714 | Val MSE: 14.7745\n",
      "Epoch 170/270 | Train MSE: 7.7384 | Val MSE: 14.5448\n",
      "Epoch 180/270 | Train MSE: 7.5792 | Val MSE: 15.3816\n",
      "Epoch 190/270 | Train MSE: 7.4428 | Val MSE: 15.3334\n",
      "Epoch 200/270 | Train MSE: 7.3266 | Val MSE: 15.3674\n",
      "Epoch 210/270 | Train MSE: 7.2070 | Val MSE: 15.2199\n",
      "Epoch 220/270 | Train MSE: 7.1113 | Val MSE: 15.3238\n",
      "Epoch 230/270 | Train MSE: 6.9776 | Val MSE: 15.1841\n",
      "Epoch 240/270 | Train MSE: 6.7612 | Val MSE: 14.9682\n",
      "Epoch 250/270 | Train MSE: 6.8054 | Val MSE: 16.0802\n",
      "Epoch 260/270 | Train MSE: 6.5632 | Val MSE: 15.3639\n",
      "Epoch 270/270 | Train MSE: 6.6221 | Val MSE: 16.3271\n",
      "Test Results:\n",
      "  Overall MSE (avg of home/away): 18.5899\n",
      "  Home Points MSE: 17.7622\n",
      "  Away Points MSE: 19.4177\n",
      "  Total Points MSE (sum): 58.9766\n"
     ]
    }
   ],
   "source": [
    "    import sys\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    import torch.nn.functional as F\n",
    "    import torch.optim as optim\n",
    "    import torch.nn as nn\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "    from data.api_fetcher import ApiFetcher\n",
    "    from model.team_embeddings import EmbeddingFetcher\n",
    "    from model.team_embeddings import TeamEmbeddingsModel\n",
    "\n",
    "    api = ApiFetcher(starting_year=2019, ending_year=2025)\n",
    "    df = api.get_dataframe(numeric=False, date=True, time_coeff=False, ids=True)\n",
    "\n",
    "    home_embeddings = trained_model.home_embedding.weight.detach().cpu().numpy()\n",
    "    away_embeddings = trained_model.away_embedding.weight.detach().cpu().numpy()\n",
    "    embeddings_fetcher = EmbeddingFetcher(home_embeddings, away_embeddings)\n",
    "\n",
    "    def prep_df(df1, target_cols=['home_pts', 'away_pts'], scaler=None):\n",
    "        team_id_cols = ['home_team_id', 'away_team_id']\n",
    "        exclude_cols = target_cols + team_id_cols + ['date', 'home_team', 'away_team']\n",
    "        numeric_cols = [col for col in df1.columns if col not in exclude_cols]\n",
    "        \n",
    "        X_numeric_raw = df1[numeric_cols].values\n",
    "        X_team_ids = df1[team_id_cols].astype(int).values\n",
    "        # Changed: Keep separate home_pts and away_pts as targets\n",
    "        y = df1[target_cols].values  # Shape: (n_samples, 2)\n",
    "        \n",
    "        if scaler is None:\n",
    "            scaler = StandardScaler()\n",
    "            X_numeric = scaler.fit_transform(X_numeric_raw)\n",
    "        else:\n",
    "            X_numeric = scaler.transform(X_numeric_raw)\n",
    "        \n",
    "        return X_numeric, X_team_ids, y, scaler, numeric_cols\n",
    "\n",
    "    class NBAEmbeddingDataset(Dataset):\n",
    "        def __init__(self, X_numeric, X_team_ids, y, fetcher):\n",
    "            self.X_numeric = torch.tensor(X_numeric, dtype=torch.float32)\n",
    "            self.X_team_ids = torch.tensor(X_team_ids, dtype=torch.long)\n",
    "            self.y = torch.tensor(y, dtype=torch.float32)  # Shape: (n_samples, 2)\n",
    "            self.fetcher = fetcher\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.y)\n",
    "    \n",
    "        def __getitem__(self, idx):\n",
    "            numeric_features = self.X_numeric[idx]\n",
    "            home_id, away_id = self.X_team_ids[idx]\n",
    "            # Fetch embeddings\n",
    "            home_emb = torch.tensor(self.fetcher.get_home_embedding(home_id), dtype=torch.float32)\n",
    "            away_emb = torch.tensor(self.fetcher.get_away_embedding(away_id), dtype=torch.float32)\n",
    "            return numeric_features, home_emb, away_emb, self.y[idx]  # y[idx] has shape (2,)\n",
    "\n",
    "    class MiniNN(nn.Module):\n",
    "        def __init__(self, num_numeric_features, embedding_dim):\n",
    "            super(MiniNN, self).__init__()\n",
    "            input_size = num_numeric_features + embedding_dim*2\n",
    "            self.fc1 = nn.Linear(input_size, 128)\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.fc3 = nn.Linear(64, 32)\n",
    "            # Changed: Output 2 values (home_pts, away_pts)\n",
    "            self.out = nn.Linear(32, 2)\n",
    "        \n",
    "        def forward(self, numeric_features, home_emb, away_emb):\n",
    "            x = torch.cat([numeric_features, home_emb, away_emb], dim=1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = F.relu(self.fc3(x))\n",
    "            return self.out(x)  # Shape: (batch_size, 2)\n",
    "\n",
    "    def train_model(df, fetcher, embedding_dim, num_epochs, lr, batch_size=64):\n",
    "        # Sort and split\n",
    "        df_sorted = df.sort_values(\"date\")\n",
    "        train_df, val_df, test_df = np.split(\n",
    "            df_sorted,\n",
    "            [int(0.7*len(df_sorted)), int(0.85*len(df_sorted))]\n",
    "        )\n",
    "    \n",
    "        X_train_num, X_train_ids, y_train, scaler, numeric_cols = prep_df(train_df)\n",
    "        X_val_num, X_val_ids, y_val, _, _ = prep_df(val_df, scaler=scaler)\n",
    "        X_test_num, X_test_ids, y_test, _, _ = prep_df(test_df, scaler=scaler)\n",
    "    \n",
    "        # Datasets\n",
    "        train_dataset = NBAEmbeddingDataset(X_train_num, X_train_ids, y_train, fetcher)\n",
    "        val_dataset = NBAEmbeddingDataset(X_val_num, X_val_ids, y_val, fetcher)\n",
    "        test_dataset = NBAEmbeddingDataset(X_test_num, X_test_ids, y_test, fetcher)\n",
    "    \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "        # Model\n",
    "        num_numeric_features = X_train_num.shape[1]\n",
    "        model = MiniNN(num_numeric_features, embedding_dim)\n",
    "    \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for X_num, home_emb, away_emb, y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(X_num, home_emb, away_emb)  # Shape: (batch_size, 2)\n",
    "                loss = criterion(pred, y)  # y has shape (batch_size, 2)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * X_num.size(0)\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for X_num, home_emb, away_emb, y in val_loader:\n",
    "                    pred = model(X_num, home_emb, away_emb)\n",
    "                    val_loss += criterion(pred, y).item() * X_num.size(0)\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "            if (epoch+1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} | Train MSE: {train_loss:.4f} | Val MSE: {val_loss:.4f}\")\n",
    "    \n",
    "        # Test evaluation with detailed metrics\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        home_loss = 0\n",
    "        away_loss = 0\n",
    "        total_loss = 0  # For sum of home + away\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_num, home_emb, away_emb, y in test_loader:\n",
    "                pred = model(X_num, home_emb, away_emb)  # Shape: (batch_size, 2)\n",
    "                \n",
    "                # Overall MSE (average of home and away)\n",
    "                test_loss += criterion(pred, y).item() * X_num.size(0)\n",
    "                \n",
    "                # Individual losses\n",
    "                home_pred, away_pred = pred[:, 0], pred[:, 1]\n",
    "                home_true, away_true = y[:, 0], y[:, 1]\n",
    "                \n",
    "                home_loss += F.mse_loss(home_pred, home_true).item() * X_num.size(0)\n",
    "                away_loss += F.mse_loss(away_pred, away_true).item() * X_num.size(0)\n",
    "                \n",
    "                # Total points loss (sum of predictions vs sum of actuals)\n",
    "                total_pred = home_pred + away_pred\n",
    "                total_true = home_true + away_true\n",
    "                total_loss += F.mse_loss(total_pred, total_true).item() * X_num.size(0)\n",
    "        \n",
    "        test_size = len(test_loader.dataset)\n",
    "        test_loss /= test_size\n",
    "        home_loss /= test_size\n",
    "        away_loss /= test_size\n",
    "        total_loss /= test_size\n",
    "        \n",
    "        print(f\"Test Results:\")\n",
    "        print(f\"  Overall MSE (avg of home/away): {test_loss:.4f}\")\n",
    "        print(f\"  Home Points MSE: {home_loss:.4f}\")\n",
    "        print(f\"  Away Points MSE: {away_loss:.4f}\")\n",
    "        print(f\"  Total Points MSE (sum): {total_loss:.4f}\")\n",
    "    \n",
    "        return model, scaler, numeric_cols, {\n",
    "            'overall_mse': test_loss,\n",
    "            'home_mse': home_loss,\n",
    "            'away_mse': away_loss,\n",
    "            'total_mse': total_loss\n",
    "        }\n",
    "\n",
    "    # Run the training\n",
    "    embedding_dim = home_embeddings.shape[1]\n",
    "    model, scaler, numeric_cols, results = train_model(\n",
    "        df, embeddings_fetcher, embedding_dim, \n",
    "        num_epochs=270, lr=0.0008991\n",
    "    )\n",
    "\n",
    "    # Function to get predictions for meta-model\n",
    "    def get_predictions(model, df, fetcher, scaler, numeric_cols):\n",
    "        \"\"\"Get home, away, and total predictions from the trained model\"\"\"\n",
    "        X_numeric, X_team_ids, _, _, _ = prep_df(df, scaler=scaler)\n",
    "        dataset = NBAEmbeddingDataset(X_numeric, X_team_ids, np.zeros((len(df), 2)), fetcher)\n",
    "        \n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_num, home_emb, away_emb, _ in DataLoader(dataset, batch_size=64, shuffle=False):\n",
    "                pred = model(X_num, home_emb, away_emb)\n",
    "                predictions.append(pred.numpy())\n",
    "        \n",
    "        predictions = np.vstack(predictions)\n",
    "        home_preds = predictions[:, 0]\n",
    "        away_preds = predictions[:, 1]\n",
    "        total_preds = home_preds + away_preds\n",
    "        \n",
    "        return home_preds, away_preds, total_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
